{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Create Coversational Agent\n",
        " -----------------------------\n",
        "1.   Choose Topic\n",
        "2.   create a prompt and create a chain that uses the prompt\n",
        "3.   Create an agent and add conversational memory\n",
        "4.   Add additional context to the agent\n",
        "5.   Add a few-shot example to the agent\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TzI2YKAgXe8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain  langchain_community langchain-openai langchain_neo4j  -q"
      ],
      "metadata": {
        "id": "7H598v_cXjT-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_neo4j import GraphCypherQAChain, Neo4jGraph\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain.tools import Tool\n",
        "from langchain import hub\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_neo4j import Neo4jChatMessageHistory, Neo4jGraph, Neo4jVector\n",
        "from uuid import uuid4"
      ],
      "metadata": {
        "id": "cFrrXnu8YfBi"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_properties(path):\n",
        "    data = {}\n",
        "    with open(path) as f:\n",
        "        for line in f:\n",
        "            if \"=\" in line:\n",
        "                k, v = line.split(\"=\", 1)\n",
        "                data[k.strip()] = v.strip()\n",
        "    return data"
      ],
      "metadata": {
        "id": "u_gOiW0_XnO3"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "props = load_properties(\"openai_key.txt\")\n",
        "\n",
        "os.environ[\"OPENAI_KEY\"] = props[\"OPENAI_KEY\"]\n",
        "os.environ[\"NEO4J_URI\"] = props[\"NEO4J_URI\"]\n",
        "os.environ[\"NEO4J_USERNAME\"] = props[\"NEO4J_USERNAME\"]\n",
        "os.environ[\"NEO4J_PASSWORD\"] = props[\"NEO4J_PASSWORD\"]\n",
        "#os.environ[\"NEO4J_DATABASE\"] = props[\"NEO4J_DATABASE\"]"
      ],
      "metadata": {
        "id": "fX7_ZFZBX9E4"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Prompt - Few-shot examples\n",
        "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
        "You are an expert Neo4j Developer translating user questions into Cypher to answer questions about movies and provide recommendations.\n",
        "Convert the user's question based on the schema.\n",
        "\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the schema.\n",
        "Do not use any other relationship types or properties that are not provided.\n",
        "For movie titles that begin with \"The\", move \"the\" to the end, For example \"The 39 Steps\" becomes \"39 Steps, The\" or \"The Matrix\" becomes \"Matrix, The\".\n",
        "\n",
        "If no data is returned, do not attempt to answer the question.\n",
        "Only respond to questions that require you to construct a Cypher statement.\n",
        "Do not include any explanations or apologies in your responses.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Find movies and genres:\n",
        "MATCH (m:Movie)-[:IN_GENRE]->(g)\n",
        "RETURN m.title, g.name\n",
        "\n",
        "Schema: {schema}\n",
        "Question: {question}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "xcEQc7jrYKv5"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cypher_generation_prompt = PromptTemplate(\n",
        "    template=CYPHER_GENERATION_TEMPLATE,\n",
        "    input_variables=[\"schema\", \"question\"],\n",
        ")"
      ],
      "metadata": {
        "id": "zHf6wDHZZTxC"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=os.getenv(\"OPENAI_KEY\"),\n",
        "    temperature=0,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "xNLJZ5OiZbRP"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = Neo4jGraph(\n",
        "    url=os.getenv(\"NEO4J_URI\"),\n",
        "    username=os.getenv(\"NEO4J_USERNAME\"),\n",
        "    password=os.getenv(\"NEO4J_PASSWORD\")\n",
        ")"
      ],
      "metadata": {
        "id": "3gqhzYTHZiZp"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create chain that uses the prompt\n",
        "cypher_chain = GraphCypherQAChain.from_llm(\n",
        "    llm,\n",
        "    graph=graph,\n",
        "    cypher_prompt=cypher_generation_prompt,\n",
        "    verbose=True,\n",
        "    allow_dangerous_requests=True\n",
        ")"
      ],
      "metadata": {
        "id": "SXBiM3ayYauZ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool.from_function(\n",
        "        name=\"Movie Plot Search\",\n",
        "        description=\"For when you need to compare a plot to a movie. The question will be a string. Return a string.\",\n",
        "        func=cypher_chain.invoke,\n",
        "    ),\n",
        "]\n"
      ],
      "metadata": {
        "id": "oYeLZyMJacTv"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Agent\n",
        "agent_prompt = hub.pull(\"hwchase17/react-chat\")\n",
        "\n",
        "custom_prompt = agent_prompt.partial(\n",
        "    additional_context=\"\"\"\n",
        "                      You are a Neo4j Movie QA Assistant.\n",
        "                      Your job is to answer questions using the graph.\n",
        "                      Graph schema:\n",
        "                      Movie(title, plot).\n",
        "                      Always give short and accurate answers.\n",
        "                      \"\"\"\n",
        "        )\n",
        "\n",
        "#print(agent_prompt.template)\n",
        "agent = create_react_agent(llm, tools, custom_prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools,handle_parsing_errors=True)"
      ],
      "metadata": {
        "id": "QPvs7jVhZ3Jl"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SESSION_ID = str(uuid4())\n",
        "print(f\"Session ID: {SESSION_ID}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ4KFzCwa_Pl",
        "outputId": "08cb7cc1-9ae2-428b-debf-647a1bc30d29"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session ID: e2e8f9a4-370a-4702-9cad-8a15ee786c9d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_memory(session_id):\n",
        "    return Neo4jChatMessageHistory(session_id=session_id, graph=graph)"
      ],
      "metadata": {
        "id": "UnPxTX7fa-a0"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding conversational memory\n",
        "chat_agent = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    get_memory,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")"
      ],
      "metadata": {
        "id": "ZNuOGdsuarnK"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while (q := input(\"> \")) != \"exit\":\n",
        "\n",
        "    response = chat_agent.invoke(\n",
        "        {\n",
        "            \"input\": q\n",
        "        },\n",
        "        {\"configurable\": {\"session_id\": SESSION_ID}},\n",
        "    )\n",
        "\n",
        "    print(response[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yxz_Bocd0n0",
        "outputId": "984fee4b-c445-4b02-9259-7b24b19351e3"
      },
      "execution_count": 67,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> details about Tom Hanks\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mMATCH (p:Person {name: \"Tom Hanks\"})\n",
            "RETURN p.dateofbirth, p.birthcity\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'p.dateofbirth': '1956-07-09', 'p.birthcity': 'Concord, California, USA'}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Tom Hanks was born on July 9, 1956, in Concord, California, USA.\n",
            "> exit\n"
          ]
        }
      ]
    }
  ]
}